{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. List\n",
    "extend, index, pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ximena', 'Aliza', 'Ayden', 'Calvin', 'Rowen', 'Sandeep']\n",
      "['Ximena', 'Ayden', 'Calvin', 'Rowen', 'Sandeep']\n"
     ]
    }
   ],
   "source": [
    "baby_names = ['Ximena', 'Aliza', 'Ayden', 'Calvin']\n",
    "\n",
    "baby_names.extend(['Rowen','Sandeep'])\n",
    "print(baby_names)\n",
    "\n",
    "# Find the position & pop\n",
    "position = baby_names.index('Aliza')\n",
    "baby_names.pop(position)\n",
    "print(baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ayden', 'Calvin', 'Rowen', 'Sandeep', 'Ximena']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(baby_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x000001CB122FB588>\n"
     ]
    }
   ],
   "source": [
    "girl_names = ['Olivia','RACHEL','HAILEY','Brielle','Samantha']\n",
    "boy_names = ['Ryan','Joshua','ETHAN','KEVIN','Samuel']\n",
    "\n",
    "pairs = zip(girl_names, boy_names)\n",
    "\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Olivia and Ryan\n",
      "1: RACHEL and Joshua\n",
      "2: HAILEY and ETHAN\n",
      "3: Brielle and KEVIN\n",
      "4: Samantha and Samuel\n"
     ]
    }
   ],
   "source": [
    "for idx, pair in enumerate(pairs):\n",
    "    # Unpack pair\n",
    "    girl_name, boy_name = pair\n",
    "    print('{}: {} and {}'.format(idx, girl_name, boy_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BRITH_YEAR  GENDER  ETHNICTY       NAME  COUNT  RANK\n",
      "0        2011  FEMALE  HISPANIC  GERALDINE     13    75\n",
      "1        2011  FEMALE  HISPANIC        GIA     21    67\n",
      "2        2011  FEMALE  HISPANIC     GIANNA     49    42\n",
      "3        2011  FEMALE  HISPANIC    GISELLE     38    51\n",
      "4        2011  FEMALE  HISPANIC      GRACE     36    53\n",
      "(4016, 6)\n",
      "(1023, 6)\n"
     ]
    }
   ],
   "source": [
    "df_name = pd.read_csv('data/baby_names.csv')\n",
    "\n",
    "df_name_2011 = df_name[(df_name.BRITH_YEAR == 2011) & (df_name.GENDER == 'FEMALE')]\n",
    "df_name_2012 = df_name[(df_name.BRITH_YEAR == 2012) & (df_name.GENDER == 'FEMALE')]\n",
    "\n",
    "print(df_name_2011.head())\n",
    "\n",
    "print(df_name_2011.shape)\n",
    "print(df_name_2012.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('ARIELLA', 65), ('SLOANE', 74), ('ARIANA', 64), ('AVA', 8), ('KAYLEE', 28), ('OLIVIA', 4), ('STEPHANIE', 41), ('ALONDRA', 72), ('ROSA', 78), ('LILY', 33), ('KATE', 38), ('IRIS', 78), ('ALEXA', 40), ('LAILA', 59), ('AMANDA', 76), ('SOPHIA', 4), ('CHLOE', 4), ('HARMONY', 35), ('GABRIELLE', 76), ('JAZMINE', 74), ('LONDON', 2), ('ABIGAIL', 19), ('MELANIE', 12), ('KATIE', 76), ('MORGAN', 71), ('AUBREY', 63), ('VIVIANA', 77), ('AUTUMN', 29), ('HAILEY', 57), ('IVY', 76), ('ANGIE', 69), ('AMY', 80), ('SAVANNA', 78), ('MADELYN', 72), ('YAEL', 70), ('ANGELINA', 44), ('STELLA', 32), ('AMIRA', 80), ('EDEN', 67), ('JULIETTE', 68), ('MADISON', 1), ('ANAYA', 43), ('KIRA', 80), ('CHARLOTTE', 77), ('VICTORIA', 19), ('ALEXANDRA', 43), ('ELIANA', 55), ('ISABELLA', 6), ('MARILYN', 78), ('MARIAMA', 33), ('EMMA', 5), ('JULIA', 45), ('ZOE', 23), ('JULIET', 55), ('DESTINY', 20), ('ALESSIA', 77), ('ISABELLA', 1), ('ALISSON', 73), ('AVIGAIL', 80)}\n"
     ]
    }
   ],
   "source": [
    "baby_names_2011 = set()\n",
    "for row in np.array(df_name_2011):\n",
    "    baby_names_2011.add((row[3], row[5]))   # name, rank\n",
    "    \n",
    "baby_names_2012 = set()\n",
    "for row in np.array(df_name_2012):\n",
    "    baby_names_2012.add((row[3], row[5]))\n",
    "    \n",
    "all_names = baby_names_2011.union(baby_names_2012)\n",
    "\n",
    "diff_names = baby_names_2011.difference(baby_names_2012)\n",
    "\n",
    "overlap_names = baby_names_2011.intersection(baby_names_2012)\n",
    "print(overlap_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 LIV\n",
      "82 LYLA\n",
      "81 ESTY\n",
      "80 LILAH\n",
      "79 ANAIS\n",
      "78 MARILYN\n",
      "77 AMINA\n",
      "76 RIHANNA\n",
      "75 JULIANA\n",
      "74 NATALY\n"
     ]
    }
   ],
   "source": [
    "names_2011 = {}\n",
    "names_2012 = {}\n",
    "\n",
    "# Loop over the girl names\n",
    "for name, rank in baby_names_2011:\n",
    "    # Add each name to the names dictionary using rank as the key\n",
    "    names_2011[rank] = name\n",
    "\n",
    "for name, rank in baby_names_2012:\n",
    "    names_2012[rank] = name\n",
    "\n",
    "# Sort the names list by rank in descending order and slice the first 10 items\n",
    "for rank in sorted(names_2012, reverse=True)[:10]:\n",
    "    print(rank, names_2012[rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISABELLA\n",
      "<class 'NoneType'>\n",
      "Not Found\n"
     ]
    }
   ],
   "source": [
    "# Safely finding by key\n",
    "\n",
    "print(names_2012.get(1))\n",
    "\n",
    "print(type(names_2012.get(100)))  # None\n",
    "print(names_2012.get(100, 'Not Found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([2011, 2012, 2013])\n",
      "dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81])\n"
     ]
    }
   ],
   "source": [
    "# nested dictionary\n",
    "girl_names = {}\n",
    "\n",
    "girl_names[2011] = names_2011\n",
    "girl_names[2012] = names_2012\n",
    "girl_names[2013] = {}\n",
    "\n",
    "print(girl_names.keys())\n",
    "print(girl_names[2011].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Kate', 2: 'Elsa', 3: 'Jessica'}\n"
     ]
    }
   ],
   "source": [
    "girl_names[2013].update([(1, 'Kate'), (2, 'Elsa'), (3, 'Jessica')])\n",
    "print(girl_names[2013])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 CORA\n",
      "2012 LIV\n",
      "2013 Jessica\n"
     ]
    }
   ],
   "source": [
    "for year in girl_names:\n",
    "    for rank in sorted(girl_names[year], reverse=True)[:1]:\n",
    "        # Check that you have a rank\n",
    "        if not rank:\n",
    "            print(year, 'No Data Available')\n",
    "            \n",
    "        # Safely print the year and the least popular name or 'Not Available'\n",
    "        print(year, girl_names[year].get(rank,'Not Available'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Kate\n",
      "2 Elsa\n",
      "3 Jessica\n"
     ]
    }
   ],
   "source": [
    "# Working with dictionaries more pythonically\n",
    "for rank, name in girl_names[2013].items():\n",
    "    print(rank, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2011\n",
      "Found Rank 1 in 2012\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionaries for data\n",
    "\n",
    "if 2011 in girl_names:\n",
    "    print('Found 2011')\n",
    "    \n",
    "# Check to see if rank 1 is in 2012\n",
    "if 1 in girl_names[2012]:\n",
    "    print('Found Rank 1 in 2012')\n",
    "else:\n",
    "    print('Rank 1 missing from 2012')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV reader / DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "baby_names = {}\n",
    "csvfile = open('data/baby_names.csv','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['49', '70', '54', '71', '84', '12', '22', '72', '47', '99', '61', '17', '14', '20', '23', '82', '6', '27', '75', '21', '66', '44', '50', '40', '13', '63', '42', '8', '1', '90', '45', '32', '98', '33', '41', '39', '89', '28', '62', '46', '97', '101', '86', '69', '64', '15', '80', '56', '10', '29', '18', '73', '60', '19', '48', '24', '11', '57', '37', '36', '91', '35', '74', '26', '81', '34', '4', '7', '68', '3', '96', '77', '16', '9', '93', '59', '30', '65', '76', '94', '25', '43', '31', '87', '5', '2', '92', '51', '79', '38', '58', '85', '100', '67', '55', '88', '95', '78', '83', '53', '52', '102'])\n"
     ]
    }
   ],
   "source": [
    "# CSV reader\n",
    "reader = csv.reader(csvfile)\n",
    "next(reader, None)  # skip the headers\n",
    "\n",
    "for row in reader:\n",
    "    baby_names[row[5]] = row[3]    # row = ['2011', 'FEMALE', 'HISPANIC', 'GIA', '21', '67']\n",
    "\n",
    "print(baby_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['49', '70', '54', '71', '84', '12', '22', '72', '47', '99', '61', '17', '14', '20', '23', '82', '6', '27', '75', '21', '66', '44', '50', '40', '13', '63', '42', '8', '1', '90', '45', '32', '98', '33', '41', '39', '89', '28', '62', '46', '97', '101', '86', '69', '64', '15', '80', '56', '10', '29', '18', '73', '60', '19', '48', '24', '11', '57', '37', '36', '91', '35', '74', '26', '81', '34', '4', '7', '68', '3', '96', '77', '16', '9', '93', '59', '30', '65', '76', '94', '25', '43', '31', '87', '5', '2', '92', '51', '79', '38', '58', '85', '100', '67', '55', '88', '95', '78', '83', '53', '52', '102'])\n"
     ]
    }
   ],
   "source": [
    "# CSV DictReader\n",
    "for row in csv.DictReader(csvfile):\n",
    "    baby_names[row['RANK']] = row['NAME']    # row = dictionary\n",
    "\n",
    "print(baby_names.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. collections module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>stationname</th>\n",
       "      <th>date</th>\n",
       "      <th>daytype</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>SUNDAY/HOLIDAY</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/02/2015</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/03/2015</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/04/2015</td>\n",
       "      <td>SUNDAY/HOLIDAY</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/05/2015</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id         stationname        date         daytype  rides\n",
       "0       40010  Austin-Forest Park  01/01/2015  SUNDAY/HOLIDAY    587\n",
       "1       40010  Austin-Forest Park  01/02/2015         WEEKDAY   1386\n",
       "2       40010  Austin-Forest Park  01/03/2015        SATURDAY    785\n",
       "3       40010  Austin-Forest Park  01/04/2015  SUNDAY/HOLIDAY    625\n",
       "4       40010  Austin-Forest Park  01/05/2015         WEEKDAY   1752"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sta = pd.read_csv('data/cta_daily_station_totals.csv')\n",
    "df_sta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = df_sta.stationname.unique()   # unique of column items\n",
    "len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Ashland-Lake': 700, 'Damen-Cermak': 700, 'California-Lake': 700, 'Harrison': 700, 'Linden': 700, 'Conservatory': 700, 'East 63rd-Cottage Grove': 700, 'Halsted/63rd': 700, 'Cicero-Cermak': 700, 'Chicago/Milwaukee': 700, 'Western-Orange': 700, 'Morgan-Lake': 700, 'Kedzie-Cermak': 700, 'Grand/Milwaukee': 700, 'Ridgeland': 700, 'Halsted-Orange': 700, 'Clinton-Forest Park': 700, 'Adams/Wabash': 700, 'Wilson': 700, '79th': 700, 'Cumberland': 700, 'Grand/State': 700, 'Rosemont': 700, '69th': 700, 'Addison-Brown': 700, 'Indiana': 700, 'Cicero-Forest Park': 700, 'Kostner': 700, 'Kedzie-Brown': 700, 'Main': 700, 'Clark/Lake': 700, 'Garfield-Dan Ryan': 700, 'Lawrence': 700, 'Ashland/63rd': 700, 'Irving Park-Brown': 700, '47th-South Elevated': 700, 'Fullerton': 700, 'Paulina': 700, 'Division/Milwaukee': 700, 'Jackson/Dearborn': 700, 'Oakton-Skokie': 700, 'LaSalle': 700, 'Cermak-McCormick Place': 700, 'Wellington': 700, 'Pulaski-Lake': 700, 'Washington/Wells': 700, 'Western-Forest Park': 700, 'Dempster': 700, 'Southport': 700, 'Jefferson Park': 700, 'Argyle': 700, 'Central Park': 700, 'Kedzie-Lake': 700, 'Sox-35th-Dan Ryan': 700, '47th-Dan Ryan': 700, 'Pulaski-Orange': 700, 'Jarvis': 700, \"Belmont-O'Hare\": 700, 'Austin-Lake': 700, 'LaSalle/Van Buren': 700, 'California-Cermak': 700, 'North/Clybourn': 700, 'Austin-Forest Park': 700, 'Diversey': 700, 'Harlem-Lake': 700, 'King Drive': 700, 'Kedzie-Midway': 700, '18th': 700, \"Addison-O'Hare\": 700, 'Monroe/Dearborn': 700, 'Forest Park': 700, 'Kimball': 700, \"Harlem-O'Hare\": 700, 'Ashland-Orange': 700, 'UIC-Halsted': 700, 'Jackson/State': 700, 'Clinton-Lake': 700, 'Rockwell': 700, 'Morse': 700, 'Washington/Dearborn': 700, \"Montrose-O'Hare\": 700, 'Kedzie-Homan-Forest Park': 700, 'Midway Airport': 700, 'South Boulevard': 700, \"Irving Park-O'Hare\": 700, 'State/Lake': 700, 'Western-Cermak': 700, 'Oak Park-Lake': 700, 'Oak Park-Forest Park': 700, 'Bryn Mawr': 700, 'Thorndale': 700, 'Harlem-Forest Park': 700, 'Howard': 700, 'Foster': 700, 'California/Milwaukee': 700, 'Central-Evanston': 700, 'Montrose-Brown': 700, 'Cermak-Chinatown': 700, 'Medical Center': 700, 'Library': 700, '43rd': 700, 'Sheridan': 700, '95th/Dan Ryan': 700, 'Noyes': 700, '51st': 700, 'Monroe/State': 700, 'Cicero-Lake': 700, 'Dempster-Skokie': 700, 'Berwyn': 700, '35th/Archer': 700, 'Western-Brown': 700, '63rd-Dan Ryan': 700, 'Merchandise Mart': 700, 'Lake/State': 700, 'Quincy/Wells': 700, 'Francisco': 700, 'Sedgwick': 700, 'Garfield-South Elevated': 700, 'Addison-North Main': 700, 'Racine': 700, 'Chicago/State': 700, '35-Bronzeville-IIT': 700, 'Madison/Wabash': 700, 'Belmont-North Main': 700, 'Chicago/Franklin': 700, 'Randolph/Wabash': 700, 'Roosevelt': 700, 'Clark/Division': 700, 'Granville': 700, 'Damen/Milwaukee': 700, 'Pulaski-Forest Park': 700, 'Central-Lake': 700, 'Armitage': 700, '87th': 700, \"O'Hare Airport\": 700, 'Western/Milwaukee': 700, 'Laramie': 700, 'Damen-Brown': 700, 'Loyola': 700, 'Davis': 700, 'Polk': 700, '54th/Cermak': 700, 'Logan Square': 700, 'Pulaski-Cermak': 700})\n"
     ]
    }
   ],
   "source": [
    "station_count = Counter(df_sta.stationname)\n",
    "print(station_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ashland-Lake', 700), ('Damen-Cermak', 700), ('California-Lake', 700), ('Harrison', 700), ('Linden', 700)]\n"
     ]
    }
   ],
   "source": [
    "# Finding most common elements\n",
    "print(station_count.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = np.array(df_sta[['date','stationname','rides']])[:1000]\n",
    "entries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defaultdict()\n",
    "# dictionary에 기본값을 정의해 키값이 없더라도 에러를 출력하지않고 기본값을 출력한다.\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a defaultdict with a default type of list: ridership\n",
    "ridership = defaultdict(list)\n",
    "\n",
    "for date, stop, riders in entries:\n",
    "    # Use the stop as the key of ridership and append the riders to its value\n",
    "    ridership[date].append((stop, riders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('01/31/2015', [('Austin-Forest Park', 953), ('Harlem-Lake', 2311), ('Pulaski-Lake', 1187), ('Quincy/Wells', 1390), ('Davis', 2766), (\"Belmont-O'Hare\", 3197), ('Jackson/Dearborn', 2738), ('Sheridan', 3563), ('Damen-Brown', 1399), ('Morse', 3559), ('35th/Archer', 1423), ('51st', 634), ('Dempster-Skokie', 869), ('Pulaski-Cermak', 812), ('LaSalle/Van Buren', 507), ('Ashland-Lake', 1225), ('Oak Park-Forest Park', 641), ('Sox-35th-Dan Ryan', 3172), ('Randolph/Wabash', 3700), ('Damen-Cermak', 922), ('Western-Forest Park', 1105), ('Cumberland', 1666), ('79th', 5170), ('Kedzie-Homan-Forest Park', 1634), ('State/Lake', 5401), ('Main', 944), ('Central-Lake', 1567), ('Ashland/63rd', 816), ('Indiana', 435), ('Western-Orange', 1834), ('Division/Milwaukee', 3372), ('Grand/State', 7804)])]\n"
     ]
    }
   ],
   "source": [
    "print(list(ridership.items())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OrderedDictionaries\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('01/01/2015', 52453), ('01/02/2015', 94310), ('01/03/2015', 58621), ('01/04/2015', 46778), ('01/05/2015', 113876), ('01/06/2015', 117591), ('01/07/2015', 87687), ('01/08/2015', 100296), ('01/09/2015', 108958), ('01/10/2015', 57727), ('01/11/2015', 46049), ('01/12/2015', 123425), ('01/13/2015', 124727), ('01/14/2015', 124723), ('01/15/2015', 127371), ('01/16/2015', 125892), ('01/17/2015', 69142), ('01/18/2015', 50461), ('01/19/2015', 83803), ('01/20/2015', 126402)]\n"
     ]
    }
   ],
   "source": [
    "ridership_date = OrderedDict()\n",
    "\n",
    "for date, stop, riders in entries:\n",
    "    # If a key does not exist in ridership_date, set it to 0\n",
    "    if not date in ridership_date:\n",
    "        ridership_date[date] = 0\n",
    "        continue\n",
    "        \n",
    "    # Add riders to the date key in ridership_date\n",
    "    ridership_date[date] += riders\n",
    "    \n",
    "print(list(ridership_date.items())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. DateTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-19 20:01:51.167632\n",
      "2019-02-19 11:01:51.167632\n",
      "2019-01-20 20:01:51.167632\n",
      "2019-03-21 20:01:51.167632\n"
     ]
    }
   ],
   "source": [
    "local_dt = datetime.now()\n",
    "print(local_dt)\n",
    "\n",
    "# Compute the UTC datetime\n",
    "utc_dt = datetime.utcnow()\n",
    "print(utc_dt)\n",
    "\n",
    "# Finding a time in the future and from the past\n",
    "glanceback = timedelta(days=30)\n",
    "print(local_dt - glanceback)\n",
    "print(local_dt + glanceback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-01 00:00:00\n",
      "01/01/2015\n",
      "2015-01-01T00:00:00\n",
      "\n",
      "2015-01-02 00:00:00\n",
      "01/02/2015\n",
      "2015-01-02T00:00:00\n",
      "\n",
      "2015-01-03 00:00:00\n",
      "01/03/2015\n",
      "2015-01-03T00:00:00\n",
      "\n",
      "2015-01-04 00:00:00\n",
      "01/04/2015\n",
      "2015-01-04T00:00:00\n",
      "\n",
      "2015-01-05 00:00:00\n",
      "01/05/2015\n",
      "2015-01-05T00:00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for date_str in entries[:5]:\n",
    "    # Convert each date to a datetime object\n",
    "    date_obj  = datetime.strptime(date_str[0], '%m/%d/%Y')\n",
    "    print(date_obj)\n",
    "    \n",
    "    # Convert to string\n",
    "    print(datetime.strftime(date_obj, '%m/%d/%Y'))\n",
    "    \n",
    "    print(datetime.isoformat(date_obj))    # ISO standard string\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {1: 3079348})\n"
     ]
    }
   ],
   "source": [
    "# Summary as the month, year, day\n",
    "\n",
    "monthly_total_rides = defaultdict(int)\n",
    "\n",
    "for date, stop, riders in entries:\n",
    "    service_datetime = datetime.strptime(date, '%m/%d/%Y')\n",
    "\n",
    "    # Add the total rides to the current amount for the month\n",
    "    monthly_total_rides[service_datetime.month] += int(riders)\n",
    "    \n",
    "print(monthly_total_rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Date', 'Primary Type', 'Location Description', 'Arrest')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfile = open('data/chicago_crime.csv', 'r')\n",
    "\n",
    "crime_data = []\n",
    "\n",
    "for row in csv.reader(csvfile):\n",
    "    # Append the date, type of crime, location description, and arrest\n",
    "    crime_data.append((row[0], row[2], row[4], row[5]))\n",
    "    \n",
    "# Remove the first element from crime_data\n",
    "crime_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1948), (2, 1862), (7, 1257)]\n"
     ]
    }
   ],
   "source": [
    "crimes_by_month = Counter()\n",
    "\n",
    "for data in crime_data:\n",
    "    \n",
    "    # Convert to datetimes\n",
    "    date = datetime.strptime(data[0], '%m/%d/%Y %I:%M:%S %p')\n",
    "    \n",
    "    # count by month\n",
    "    crimes_by_month[date.month] += 1\n",
    "    \n",
    "# most common months for crime\n",
    "print(crimes_by_month.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['APARTMENT', 'STREET', 'RESIDENCE', 'CONSTRUCTION SITE', 'APARTMENT', 'STREET', 'VEHICLE NON-COMMERCIAL', 'STREET', 'APARTMENT', 'STREET']\n"
     ]
    }
   ],
   "source": [
    "# locations by month\n",
    "locations_by_month = defaultdict(list)\n",
    "\n",
    "for row in crime_data:\n",
    "    date = datetime.strptime(row[0], '%m/%d/%Y %I:%M:%S %p')\n",
    "    \n",
    "    # If the year is 2016 \n",
    "    if date.year == 2016:\n",
    "        # Set the dictionary key to the month and add the location\n",
    "        locations_by_month[date.month].append(row[2])\n",
    "    \n",
    "print(locations_by_month[12][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [('STREET', 196), ('RESIDENCE', 160), ('APARTMENT', 153), ('SIDEWALK', 72), ('PARKING LOT/GARAGE(NON.RESID.)', 43)]\n",
      "2 [('STREET', 188), ('RESIDENCE', 159), ('APARTMENT', 144), ('SIDEWALK', 73), ('OTHER', 40)]\n",
      "3 [('STREET', 240), ('RESIDENCE', 190), ('APARTMENT', 139), ('SIDEWALK', 99), ('OTHER', 52)]\n",
      "4 [('STREET', 213), ('RESIDENCE', 171), ('APARTMENT', 152), ('SIDEWALK', 96), ('OTHER', 40)]\n",
      "5 [('STREET', 241), ('RESIDENCE', 175), ('APARTMENT', 128), ('SIDEWALK', 111), ('OTHER', 41)]\n",
      "6 [('STREET', 245), ('RESIDENCE', 164), ('APARTMENT', 159), ('SIDEWALK', 123), ('PARKING LOT/GARAGE(NON.RESID.)', 44)]\n",
      "7 [('STREET', 309), ('RESIDENCE', 177), ('APARTMENT', 166), ('SIDEWALK', 125), ('PARKING LOT/GARAGE(NON.RESID.)', 47)]\n",
      "8 [('STREET', 280), ('RESIDENCE', 199), ('APARTMENT', 144), ('SIDEWALK', 109), ('OTHER', 47)]\n",
      "9 [('STREET', 279), ('RESIDENCE', 183), ('APARTMENT', 144), ('SIDEWALK', 121), ('OTHER', 39)]\n",
      "10 [('STREET', 248), ('RESIDENCE', 206), ('APARTMENT', 122), ('SIDEWALK', 92), ('OTHER', 62)]\n",
      "11 [('STREET', 236), ('RESIDENCE', 182), ('APARTMENT', 154), ('SIDEWALK', 75), ('OTHER', 41)]\n",
      "12 [('STREET', 207), ('RESIDENCE', 158), ('APARTMENT', 136), ('OTHER', 47), ('SIDEWALK', 46)]\n"
     ]
    }
   ],
   "source": [
    "# Find the Most Common Crimes by Location Type by Month in 2016\n",
    "for month, locations in locations_by_month.items():    \n",
    "    location_count = Counter(locations)\n",
    "    print(month, location_count.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['11', '25', '8', '24', '1', '31', '7', '19', '18', '5', '17', '12', '3', '2', '14', '20', '4', '22', '6', '16', '15', '9', '10'])\n"
     ]
    }
   ],
   "source": [
    "# crimes by district\n",
    "csvfile = open('data/chicago_crime.csv', 'r')\n",
    "\n",
    "crimes_by_district = defaultdict(list)\n",
    "\n",
    "for row in csv.DictReader(csvfile):\n",
    "    # Pop the district from each row\n",
    "    district = row.pop('District')\n",
    "    \n",
    "    # Append the rest of the data to the list for proper district in crimes_by_district\n",
    "    crimes_by_district[district].append(row)\n",
    "    \n",
    "print(crimes_by_district.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Location Description': 'RESIDENCE-GARAGE', 'Date': '02/15/2016 04:45:00 AM', 'Arrest': 'false', 'Primary Type': 'BURGLARY', 'Domestic': 'false', 'Block': '029XX N LOTUS AVE', 'Description': 'FORCIBLE ENTRY'}, {'Location Description': 'SCHOOL, PUBLIC, BUILDING', 'Date': '02/13/2017 10:45:00 AM', 'Arrest': 'false', 'Primary Type': 'CRIMINAL DAMAGE', 'Domestic': 'false', 'Block': '014XX N LEAMINGTON AVE', 'Description': 'TO PROPERTY'}, {'Location Description': 'APARTMENT', 'Date': '07/17/2016 11:25:00 AM', 'Arrest': 'false', 'Primary Type': 'CRIMINAL DAMAGE', 'Domestic': 'false', 'Block': '049XX W ST PAUL AVE', 'Description': 'TO PROPERTY'}, {'Location Description': 'APARTMENT', 'Date': '02/05/2017 05:30:00 AM', 'Arrest': 'true', 'Primary Type': 'BATTERY', 'Domestic': 'true', 'Block': '051XX W DIVERSEY AVE', 'Description': 'DOMESTIC BATTERY SIMPLE'}, {'Location Description': 'RESIDENTIAL YARD (FRONT/BACK)', 'Date': '11/07/2016 10:30:00 AM', 'Arrest': 'false', 'Primary Type': 'THEFT', 'Domestic': 'false', 'Block': '048XX W ALTGELD ST', 'Description': '$500 AND UNDER'}]\n"
     ]
    }
   ],
   "source": [
    "print(crimes_by_district['25'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 Counter({2016: 275, 2017: 53})\n",
      "25 Counter({2016: 150, 2017: 26})\n",
      "8 Counter({2016: 124, 2017: 26})\n",
      "24 Counter({2016: 51, 2017: 10})\n",
      "1 Counter({2016: 124, 2017: 15})\n",
      "31 Counter({2016: 1})\n",
      "7 Counter({2016: 181, 2017: 27})\n",
      "19 Counter({2016: 88, 2017: 11})\n",
      "18 Counter({2016: 92, 2017: 17})\n",
      "5 Counter({2016: 149, 2017: 30})\n",
      "17 Counter({2016: 38, 2017: 5})\n",
      "12 Counter({2016: 72, 2017: 9})\n",
      "3 Counter({2016: 98, 2017: 18})\n",
      "2 Counter({2016: 84, 2017: 15})\n",
      "14 Counter({2016: 59, 2017: 8})\n",
      "20 Counter({2016: 27, 2017: 8})\n",
      "4 Counter({2016: 134, 2017: 15})\n",
      "22 Counter({2016: 78, 2017: 12})\n",
      "6 Counter({2016: 157, 2017: 32})\n",
      "16 Counter({2016: 66, 2017: 9})\n",
      "15 Counter({2016: 154, 2017: 16})\n",
      "9 Counter({2016: 116, 2017: 17})\n",
      "10 Counter({2016: 144, 2017: 20})\n"
     ]
    }
   ],
   "source": [
    "# Arrest count by District by Year\n",
    "for district, crimes in crimes_by_district.items():\n",
    "    year_count = Counter()\n",
    "\n",
    "    for crime in crimes:\n",
    "        # If there was an arrest\n",
    "        if crime['Arrest'] == 'true':\n",
    "            year = datetime.strptime(crime['Date'], '%m/%d/%Y %I:%M:%S %p').year\n",
    "            year_count[year] += 1\n",
    "            \n",
    "    print(district, year_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9195\n"
     ]
    }
   ],
   "source": [
    "csvfile = open('data/chicago_crime.csv', 'r')\n",
    "\n",
    "crimes_by_block = defaultdict(list)\n",
    "\n",
    "for row in csv.DictReader(csvfile):\n",
    "    crimes_by_block[row['Block']].append(row['Primary Type'])\n",
    "    \n",
    "print(len(crimes_by_block.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CRIMINAL TRESPASS', 'ROBBERY', 'CRIMINAL DAMAGE', 'DECEPTIVE PRACTICE', 'OTHER OFFENSE', 'THEFT', 'BATTERY', 'ASSAULT'}\n",
      "{'PUBLIC PEACE VIOLATION', 'CRIMINAL TRESPASS', 'OTHER OFFENSE', 'CRIMINAL DAMAGE', 'DECEPTIVE PRACTICE', 'THEFT', 'NARCOTICS', 'ASSAULT'}\n",
      "{'BATTERY', 'ROBBERY'}\n"
     ]
    }
   ],
   "source": [
    "n_state_st_crimes = set(crimes_by_block['001XX N STATE ST'])\n",
    "print(n_state_st_crimes)\n",
    "\n",
    "w_terminal_st_crimes = set(crimes_by_block['0000X W TERMINAL ST'])\n",
    "print(w_terminal_st_crimes)\n",
    "\n",
    "# Find the differences\n",
    "crime_differences = n_state_st_crimes.difference(w_terminal_st_crimes)\n",
    "print(crime_differences)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
