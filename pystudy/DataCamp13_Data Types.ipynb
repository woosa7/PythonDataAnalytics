{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. List\n",
    "extend, index, pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ximena', 'Aliza', 'Ayden', 'Calvin', 'Rowen', 'Sandeep']\n",
      "['Ximena', 'Ayden', 'Calvin', 'Rowen', 'Sandeep']\n"
     ]
    }
   ],
   "source": [
    "baby_names = ['Ximena', 'Aliza', 'Ayden', 'Calvin']\n",
    "\n",
    "baby_names.extend(['Rowen','Sandeep'])\n",
    "print(baby_names)\n",
    "\n",
    "# Find the position & pop\n",
    "position = baby_names.index('Aliza')\n",
    "baby_names.pop(position)\n",
    "print(baby_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ayden', 'Calvin', 'Rowen', 'Sandeep', 'Ximena']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(baby_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x0000026A60D54F48>\n"
     ]
    }
   ],
   "source": [
    "girl_names = ['Olivia','RACHEL','HAILEY','Brielle','Samantha']\n",
    "boy_names = ['Ryan','Joshua','ETHAN','KEVIN','Samuel']\n",
    "\n",
    "pairs = zip(girl_names, boy_names)\n",
    "\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Olivia and Ryan\n",
      "1: RACHEL and Joshua\n",
      "2: HAILEY and ETHAN\n",
      "3: Brielle and KEVIN\n",
      "4: Samantha and Samuel\n"
     ]
    }
   ],
   "source": [
    "for idx, pair in enumerate(pairs):\n",
    "    # Unpack pair\n",
    "    girl_name, boy_name = pair\n",
    "    print('{}: {} and {}'.format(idx, girl_name, boy_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   BRITH_YEAR  GENDER  ETHNICTY       NAME  COUNT  RANK\n",
      "0        2011  FEMALE  HISPANIC  GERALDINE     13    75\n",
      "1        2011  FEMALE  HISPANIC        GIA     21    67\n",
      "2        2011  FEMALE  HISPANIC     GIANNA     49    42\n",
      "3        2011  FEMALE  HISPANIC    GISELLE     38    51\n",
      "4        2011  FEMALE  HISPANIC      GRACE     36    53\n",
      "(4016, 6)\n",
      "(1023, 6)\n"
     ]
    }
   ],
   "source": [
    "df_name = pd.read_csv('data/baby_names.csv')\n",
    "\n",
    "df_name_2011 = df_name[(df_name.BRITH_YEAR == 2011) & (df_name.GENDER == 'FEMALE')]\n",
    "df_name_2012 = df_name[(df_name.BRITH_YEAR == 2012) & (df_name.GENDER == 'FEMALE')]\n",
    "\n",
    "print(df_name_2011.head())\n",
    "\n",
    "print(df_name_2011.shape)\n",
    "print(df_name_2012.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('KIRA', 80), ('EDEN', 67), ('GABRIELLE', 76), ('SOPHIA', 4), ('STELLA', 32), ('AVA', 8), ('HARMONY', 35), ('AUBREY', 63), ('HAILEY', 57), ('SAVANNA', 78), ('AVIGAIL', 80), ('ANGELINA', 44), ('JAZMINE', 74), ('ISABELLA', 1), ('ABIGAIL', 19), ('MARIAMA', 33), ('ALEXA', 40), ('EMMA', 5), ('ALISSON', 73), ('ANGIE', 69), ('AUTUMN', 29), ('IVY', 76), ('OLIVIA', 4), ('IRIS', 78), ('MARILYN', 78), ('DESTINY', 20), ('ISABELLA', 6), ('MADISON', 1), ('JULIA', 45), ('ELIANA', 55), ('YAEL', 70), ('SLOANE', 74), ('MELANIE', 12), ('LILY', 33), ('AMY', 80), ('ALONDRA', 72), ('ROSA', 78), ('LAILA', 59), ('STEPHANIE', 41), ('ARIANA', 64), ('JULIETTE', 68), ('LONDON', 2), ('AMANDA', 76), ('ZOE', 23), ('CHARLOTTE', 77), ('CHLOE', 4), ('KATIE', 76), ('KATE', 38), ('JULIET', 55), ('KAYLEE', 28), ('MORGAN', 71), ('VICTORIA', 19), ('ANAYA', 43), ('VIVIANA', 77), ('ALESSIA', 77), ('AMIRA', 80), ('ARIELLA', 65), ('ALEXANDRA', 43), ('MADELYN', 72)}\n"
     ]
    }
   ],
   "source": [
    "baby_names_2011 = set()\n",
    "for row in np.array(df_name_2011):\n",
    "    baby_names_2011.add((row[3], row[5]))   # name, rank\n",
    "    \n",
    "baby_names_2012 = set()\n",
    "for row in np.array(df_name_2012):\n",
    "    baby_names_2012.add((row[3], row[5]))\n",
    "    \n",
    "all_names = baby_names_2011.union(baby_names_2012)\n",
    "\n",
    "diff_names = baby_names_2011.difference(baby_names_2012)\n",
    "\n",
    "overlap_names = baby_names_2011.intersection(baby_names_2012)\n",
    "print(overlap_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 MARYAM\n",
      "82 ARIEL\n",
      "81 ATHENA\n",
      "80 LEORA\n",
      "79 ADA\n",
      "78 ELISA\n",
      "77 ALESSIA\n",
      "76 NOEMI\n",
      "75 ALANI\n",
      "74 ANASTASIA\n"
     ]
    }
   ],
   "source": [
    "names_2011 = {}\n",
    "names_2012 = {}\n",
    "\n",
    "# Loop over the girl names\n",
    "for name, rank in baby_names_2011:\n",
    "    # Add each name to the names dictionary using rank as the key\n",
    "    names_2011[rank] = name\n",
    "\n",
    "for name, rank in baby_names_2012:\n",
    "    names_2012[rank] = name\n",
    "\n",
    "# Sort the names list by rank in descending order and slice the first 10 items\n",
    "for rank in sorted(names_2012, reverse=True)[:10]:\n",
    "    print(rank, names_2012[rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHLOE\n",
      "<class 'NoneType'>\n",
      "Not Found\n"
     ]
    }
   ],
   "source": [
    "# Safely finding by key\n",
    "\n",
    "print(names_2012.get(1))\n",
    "\n",
    "print(type(names_2012.get(100)))  # None\n",
    "print(names_2012.get(100, 'Not Found'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([2011, 2012, 2013])\n",
      "dict_keys([76, 52, 4, 10, 11, 67, 78, 72, 77, 36, 37, 71, 14, 58, 57, 61, 68, 35, 74, 79, 41, 13, 17, 81, 34, 45, 56, 62, 59, 46, 29, 39, 43, 65, 49, 75, 2, 42, 80, 38, 28, 63, 66, 30, 60, 40, 73, 53, 3, 18, 5, 16, 32, 50, 25, 7, 21, 69, 1, 12, 27, 31, 26, 44, 24, 23, 6, 19, 33, 64, 15, 9, 55, 20, 22, 48, 8, 54, 70, 47, 51])\n"
     ]
    }
   ],
   "source": [
    "# nested dictionary\n",
    "girl_names = {}\n",
    "\n",
    "girl_names[2011] = names_2011\n",
    "girl_names[2012] = names_2012\n",
    "girl_names[2013] = {}\n",
    "\n",
    "print(girl_names.keys())\n",
    "print(girl_names[2011].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Kate', 2: 'Elsa', 3: 'Jessica'}\n"
     ]
    }
   ],
   "source": [
    "girl_names[2013].update([(1, 'Kate'), (2, 'Elsa'), (3, 'Jessica')])\n",
    "print(girl_names[2013])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 ANGELICA\n",
      "2012 MARYAM\n",
      "2013 Jessica\n"
     ]
    }
   ],
   "source": [
    "for year in girl_names:\n",
    "    for rank in sorted(girl_names[year], reverse=True)[:1]:\n",
    "        # Check that you have a rank\n",
    "        if not rank:\n",
    "            print(year, 'No Data Available')\n",
    "            \n",
    "        # Safely print the year and the least popular name or 'Not Available'\n",
    "        print(year, girl_names[year].get(rank,'Not Available'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Kate\n",
      "2 Elsa\n",
      "3 Jessica\n"
     ]
    }
   ],
   "source": [
    "# Working with dictionaries more pythonically\n",
    "for rank, name in girl_names[2013].items():\n",
    "    print(rank, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2011\n",
      "Found Rank 1 in 2012\n"
     ]
    }
   ],
   "source": [
    "# Checking dictionaries for data\n",
    "\n",
    "if 2011 in girl_names:\n",
    "    print('Found 2011')\n",
    "    \n",
    "# Check to see if rank 1 is in 2012\n",
    "if 1 in girl_names[2012]:\n",
    "    print('Found Rank 1 in 2012')\n",
    "else:\n",
    "    print('Rank 1 missing from 2012')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV reader / DictReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "baby_names = {}\n",
    "csvfile = open('data/baby_names.csv','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['75', '67', '42', '51', '53', '62', '8', '74', '71', '78', '73', '72', '77', '60', '1', '70', '61', '65', '58', '41', '76', '68', '48', '55', '40', '66', '64', '34', '44', '57', '63', '33', '31', '20', '69', '35', '13', '52', '59', '39', '9', '27', '10', '56', '12', '2', '25', '18', '14', '38', '28', '6', '3', '19', '45', '47', '11', '79', '17', '43', '80', '37', '81', '46', '5', '22', '50', '21', '30', '24', '54', '15', '36', '23', '7', '16', '49', '29', '4', '32', '26', '92', '90', '82', '91', '88', '89', '94', '83', '93', '84', '87', '85', '86', '96', '97', '95', '99', '98', '100', '101', '102'])\n"
     ]
    }
   ],
   "source": [
    "# CSV reader\n",
    "reader = csv.reader(csvfile)\n",
    "next(reader, None)  # skip the headers\n",
    "\n",
    "for row in reader:\n",
    "    baby_names[row[5]] = row[3]    # row = ['2011', 'FEMALE', 'HISPANIC', 'GIA', '21', '67']\n",
    "\n",
    "print(baby_names.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['75', '67', '42', '51', '53', '62', '8', '74', '71', '78', '73', '72', '77', '60', '1', '70', '61', '65', '58', '41', '76', '68', '48', '55', '40', '66', '64', '34', '44', '57', '63', '33', '31', '20', '69', '35', '13', '52', '59', '39', '9', '27', '10', '56', '12', '2', '25', '18', '14', '38', '28', '6', '3', '19', '45', '47', '11', '79', '17', '43', '80', '37', '81', '46', '5', '22', '50', '21', '30', '24', '54', '15', '36', '23', '7', '16', '49', '29', '4', '32', '26', '92', '90', '82', '91', '88', '89', '94', '83', '93', '84', '87', '85', '86', '96', '97', '95', '99', '98', '100', '101', '102'])\n"
     ]
    }
   ],
   "source": [
    "# CSV DictReader\n",
    "for row in csv.DictReader(csvfile):\n",
    "    baby_names[row['RANK']] = row['NAME']    # row = dictionary\n",
    "\n",
    "print(baby_names.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. collections module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>stationname</th>\n",
       "      <th>date</th>\n",
       "      <th>daytype</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/01/2015</td>\n",
       "      <td>SUNDAY/HOLIDAY</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/02/2015</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>1386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/03/2015</td>\n",
       "      <td>SATURDAY</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/04/2015</td>\n",
       "      <td>SUNDAY/HOLIDAY</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40010</td>\n",
       "      <td>Austin-Forest Park</td>\n",
       "      <td>01/05/2015</td>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>1752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id         stationname        date         daytype  rides\n",
       "0       40010  Austin-Forest Park  01/01/2015  SUNDAY/HOLIDAY    587\n",
       "1       40010  Austin-Forest Park  01/02/2015         WEEKDAY   1386\n",
       "2       40010  Austin-Forest Park  01/03/2015        SATURDAY    785\n",
       "3       40010  Austin-Forest Park  01/04/2015  SUNDAY/HOLIDAY    625\n",
       "4       40010  Austin-Forest Park  01/05/2015         WEEKDAY   1752"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sta = pd.read_csv('data/cta_daily_station_totals.csv')\n",
    "df_sta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = df_sta.stationname.unique()   # unique of column items\n",
    "len(stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Austin-Forest Park': 700, 'Harlem-Lake': 700, 'Pulaski-Lake': 700, 'Quincy/Wells': 700, 'Davis': 700, \"Belmont-O'Hare\": 700, 'Jackson/Dearborn': 700, 'Sheridan': 700, 'Damen-Brown': 700, 'Morse': 700, '35th/Archer': 700, '51st': 700, 'Dempster-Skokie': 700, 'Pulaski-Cermak': 700, 'LaSalle/Van Buren': 700, 'Ashland-Lake': 700, 'Oak Park-Forest Park': 700, 'Sox-35th-Dan Ryan': 700, 'Randolph/Wabash': 700, 'Damen-Cermak': 700, 'Western-Forest Park': 700, 'Cumberland': 700, '79th': 700, 'Kedzie-Homan-Forest Park': 700, 'State/Lake': 700, 'Main': 700, 'Central-Lake': 700, 'Ashland/63rd': 700, 'Indiana': 700, 'Western-Orange': 700, 'Division/Milwaukee': 700, 'Grand/State': 700, 'Berwyn': 700, 'UIC-Halsted': 700, 'Southport': 700, 'Washington/Dearborn': 700, 'Clark/Lake': 700, 'Forest Park': 700, 'Noyes': 700, 'Cicero-Cermak': 700, 'Clinton-Forest Park': 700, 'California-Cermak': 700, '95th/Dan Ryan': 700, 'Merchandise Mart': 700, 'Racine': 700, 'Cicero-Lake': 700, 'Grand/Milwaukee': 700, 'Garfield-South Elevated': 700, 'Foster': 700, 'Diversey': 700, 'Wilson': 700, \"Irving Park-O'Hare\": 700, 'Jackson/State': 700, 'California/Milwaukee': 700, '54th/Cermak': 700, 'Damen/Milwaukee': 700, 'Kostner': 700, 'Ridgeland': 700, 'Clark/Division': 700, 'Madison/Wabash': 700, 'North/Clybourn': 700, 'Armitage': 700, 'Western/Milwaukee': 700, 'Adams/Wabash': 700, 'Dempster': 700, 'Laramie': 700, 'Chicago/Franklin': 700, 'East 63rd-Cottage Grove': 700, 'Washington/Wells': 700, 'Western-Cermak': 700, \"Harlem-O'Hare\": 700, 'Granville': 700, 'Lawrence': 700, 'Central Park': 700, 'Monroe/Dearborn': 700, 'Sedgwick': 700, 'Medical Center': 700, 'Rosemont': 700, '18th': 700, 'South Boulevard': 700, 'Library': 700, 'Francisco': 700, 'Thorndale': 700, \"O'Hare Airport\": 700, 'Howard': 700, '63rd-Dan Ryan': 700, 'Pulaski-Forest Park': 700, 'Midway Airport': 700, 'Halsted/63rd': 700, 'Pulaski-Orange': 700, 'Cicero-Forest Park': 700, 'Harlem-Forest Park': 700, '69th': 700, 'Cermak-Chinatown': 700, 'Rockwell': 700, 'Logan Square': 700, 'Polk': 700, 'Kedzie-Cermak': 700, 'Linden': 700, 'Ashland-Orange': 700, 'Kedzie-Lake': 700, '47th-South Elevated': 700, 'Monroe/State': 700, '35-Bronzeville-IIT': 700, 'Halsted-Orange': 700, 'King Drive': 700, 'Kedzie-Midway': 700, 'Clinton-Lake': 700, 'Garfield-Dan Ryan': 700, 'Kedzie-Brown': 700, 'Jarvis': 700, 'Argyle': 700, 'Wellington': 700, 'Fullerton': 700, '47th-Dan Ryan': 700, \"Addison-O'Hare\": 700, 'Central-Evanston': 700, 'Austin-Lake': 700, '43rd': 700, 'Jefferson Park': 700, 'Kimball': 700, 'Loyola': 700, 'Paulina': 700, 'Belmont-North Main': 700, \"Montrose-O'Hare\": 700, 'LaSalle': 700, 'Oak Park-Lake': 700, 'California-Lake': 700, 'Bryn Mawr': 700, 'Roosevelt': 700, 'Chicago/Milwaukee': 700, 'Addison-North Main': 700, '87th': 700, 'Addison-Brown': 700, 'Chicago/State': 700, 'Irving Park-Brown': 700, 'Western-Brown': 700, 'Harrison': 700, 'Montrose-Brown': 700, 'Morgan-Lake': 700, 'Lake/State': 700, 'Conservatory': 700, 'Oakton-Skokie': 700, 'Cermak-McCormick Place': 700})\n"
     ]
    }
   ],
   "source": [
    "station_count = Counter(df_sta.stationname)\n",
    "print(station_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Austin-Forest Park', 700), ('Harlem-Lake', 700), ('Pulaski-Lake', 700), ('Quincy/Wells', 700), ('Davis', 700)]\n"
     ]
    }
   ],
   "source": [
    "# Finding most common elements\n",
    "print(station_count.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = np.array(df_sta[['date','stationname','rides']])[:1000]\n",
    "entries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaultdict()\n",
    "# dictionary에 기본값을 정의해 키값이 없더라도 에러를 출력하지않고 기본값을 출력한다.\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a defaultdict with a default type of list: ridership\n",
    "ridership = defaultdict(list)\n",
    "\n",
    "for date, stop, riders in entries:\n",
    "    # Use the stop as the key of ridership and append the riders to its value\n",
    "    ridership[date].append((stop, riders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('01/01/2015', [('Austin-Forest Park', 587), ('Harlem-Lake', 1106), ('Pulaski-Lake', 811), ('Quincy/Wells', 1117), ('Davis', 1400), (\"Belmont-O'Hare\", 2023), ('Jackson/Dearborn', 1730), ('Sheridan', 2616), ('Damen-Brown', 751), ('Morse', 2433), ('35th/Archer', 862), ('51st', 430), ('Dempster-Skokie', 542), ('Pulaski-Cermak', 491), ('LaSalle/Van Buren', 270), ('Ashland-Lake', 833), ('Oak Park-Forest Park', 416), ('Sox-35th-Dan Ryan', 1862), ('Randolph/Wabash', 2267), ('Damen-Cermak', 451), ('Western-Forest Park', 673), ('Cumberland', 1053), ('79th', 3641), ('Kedzie-Homan-Forest Park', 1151), ('State/Lake', 3566), ('Main', 468), ('Central-Lake', 985), ('Ashland/63rd', 547), ('Indiana', 319), ('Western-Orange', 1029), ('Division/Milwaukee', 2714), ('Grand/State', 12152), ('Berwyn', 1744)])]\n"
     ]
    }
   ],
   "source": [
    "print(list(ridership.items())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OrderedDictionaries\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('01/01/2015', 52453), ('01/02/2015', 94310), ('01/03/2015', 58621), ('01/04/2015', 46778), ('01/05/2015', 113876), ('01/06/2015', 117591), ('01/07/2015', 87687), ('01/08/2015', 100296), ('01/09/2015', 108958), ('01/10/2015', 57727), ('01/11/2015', 46049), ('01/12/2015', 123425), ('01/13/2015', 124727), ('01/14/2015', 124723), ('01/15/2015', 127371), ('01/16/2015', 125892), ('01/17/2015', 69142), ('01/18/2015', 50461), ('01/19/2015', 83803), ('01/20/2015', 126402)]\n"
     ]
    }
   ],
   "source": [
    "ridership_date = OrderedDict()\n",
    "\n",
    "for date, stop, riders in entries:\n",
    "    # If a key does not exist in ridership_date, set it to 0\n",
    "    if not date in ridership_date:\n",
    "        ridership_date[date] = 0\n",
    "        continue\n",
    "        \n",
    "    # Add riders to the date key in ridership_date\n",
    "    ridership_date[date] += riders\n",
    "    \n",
    "print(list(ridership_date.items())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. DateTimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-01 16:49:57.465794\n",
      "2019-04-01 07:49:57.465794\n",
      "2019-03-02 16:49:57.465794\n",
      "2019-05-01 16:49:57.465794\n"
     ]
    }
   ],
   "source": [
    "local_dt = datetime.now()\n",
    "print(local_dt)\n",
    "\n",
    "# Compute the UTC datetime\n",
    "utc_dt = datetime.utcnow()\n",
    "print(utc_dt)\n",
    "\n",
    "# Finding a time in the future and from the past\n",
    "glanceback = timedelta(days=30)\n",
    "print(local_dt - glanceback)\n",
    "print(local_dt + glanceback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-01-01 00:00:00\n",
      "01/01/2015\n",
      "2015-01-01T00:00:00\n",
      "\n",
      "2015-01-02 00:00:00\n",
      "01/02/2015\n",
      "2015-01-02T00:00:00\n",
      "\n",
      "2015-01-03 00:00:00\n",
      "01/03/2015\n",
      "2015-01-03T00:00:00\n",
      "\n",
      "2015-01-04 00:00:00\n",
      "01/04/2015\n",
      "2015-01-04T00:00:00\n",
      "\n",
      "2015-01-05 00:00:00\n",
      "01/05/2015\n",
      "2015-01-05T00:00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for date_str in entries[:5]:\n",
    "    # Convert each date to a datetime object\n",
    "    date_obj  = datetime.strptime(date_str[0], '%m/%d/%Y')\n",
    "    print(date_obj)\n",
    "    \n",
    "    # Convert to string\n",
    "    print(datetime.strftime(date_obj, '%m/%d/%Y'))\n",
    "    \n",
    "    print(datetime.isoformat(date_obj))    # ISO standard string\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {1: 3079348})\n"
     ]
    }
   ],
   "source": [
    "# Summary as the month, year, day\n",
    "\n",
    "monthly_total_rides = defaultdict(int)\n",
    "\n",
    "for date, stop, riders in entries:\n",
    "    service_datetime = datetime.strptime(date, '%m/%d/%Y')\n",
    "\n",
    "    # Add the total rides to the current amount for the month\n",
    "    monthly_total_rides[service_datetime.month] += int(riders)\n",
    "    \n",
    "print(monthly_total_rides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Date', 'Primary Type', 'Location Description', 'Arrest')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csvfile = open('data/chicago_crime.csv', 'r')\n",
    "\n",
    "crime_data = []\n",
    "\n",
    "for row in csv.reader(csvfile):\n",
    "    # Append the date, type of crime, location description, and arrest\n",
    "    crime_data.append((row[0], row[2], row[4], row[5]))\n",
    "    \n",
    "# Remove the first element from crime_data\n",
    "crime_data.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1948), (2, 1862), (7, 1257)]\n"
     ]
    }
   ],
   "source": [
    "crimes_by_month = Counter()\n",
    "\n",
    "for data in crime_data:\n",
    "    \n",
    "    # Convert to datetimes\n",
    "    date = datetime.strptime(data[0], '%m/%d/%Y %I:%M:%S %p')\n",
    "    \n",
    "    # count by month\n",
    "    crimes_by_month[date.month] += 1\n",
    "    \n",
    "# most common months for crime\n",
    "print(crimes_by_month.most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['APARTMENT', 'STREET', 'RESIDENCE', 'CONSTRUCTION SITE', 'APARTMENT', 'STREET', 'VEHICLE NON-COMMERCIAL', 'STREET', 'APARTMENT', 'STREET']\n"
     ]
    }
   ],
   "source": [
    "# locations by month\n",
    "locations_by_month = defaultdict(list)\n",
    "\n",
    "for row in crime_data:\n",
    "    date = datetime.strptime(row[0], '%m/%d/%Y %I:%M:%S %p')\n",
    "    \n",
    "    # If the year is 2016 \n",
    "    if date.year == 2016:\n",
    "        # Set the dictionary key to the month and add the location\n",
    "        locations_by_month[date.month].append(row[2])\n",
    "    \n",
    "print(locations_by_month[12][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [('STREET', 241), ('RESIDENCE', 175), ('APARTMENT', 128), ('SIDEWALK', 111), ('OTHER', 41)]\n",
      "3 [('STREET', 240), ('RESIDENCE', 190), ('APARTMENT', 139), ('SIDEWALK', 99), ('OTHER', 52)]\n",
      "4 [('STREET', 213), ('RESIDENCE', 171), ('APARTMENT', 152), ('SIDEWALK', 96), ('OTHER', 40)]\n",
      "6 [('STREET', 245), ('RESIDENCE', 164), ('APARTMENT', 159), ('SIDEWALK', 123), ('PARKING LOT/GARAGE(NON.RESID.)', 44)]\n",
      "7 [('STREET', 309), ('RESIDENCE', 177), ('APARTMENT', 166), ('SIDEWALK', 125), ('OTHER', 47)]\n",
      "10 [('STREET', 248), ('RESIDENCE', 206), ('APARTMENT', 122), ('SIDEWALK', 92), ('OTHER', 62)]\n",
      "12 [('STREET', 207), ('RESIDENCE', 158), ('APARTMENT', 136), ('OTHER', 47), ('SIDEWALK', 46)]\n",
      "1 [('STREET', 196), ('RESIDENCE', 160), ('APARTMENT', 153), ('SIDEWALK', 72), ('PARKING LOT/GARAGE(NON.RESID.)', 43)]\n",
      "9 [('STREET', 279), ('RESIDENCE', 183), ('APARTMENT', 144), ('SIDEWALK', 121), ('OTHER', 39)]\n",
      "11 [('STREET', 236), ('RESIDENCE', 182), ('APARTMENT', 154), ('SIDEWALK', 75), ('OTHER', 41)]\n",
      "8 [('STREET', 280), ('RESIDENCE', 199), ('APARTMENT', 144), ('SIDEWALK', 109), ('OTHER', 47)]\n",
      "2 [('STREET', 188), ('RESIDENCE', 159), ('APARTMENT', 144), ('SIDEWALK', 73), ('OTHER', 40)]\n"
     ]
    }
   ],
   "source": [
    "# Find the Most Common Crimes by Location Type by Month in 2016\n",
    "for month, locations in locations_by_month.items():    \n",
    "    location_count = Counter(locations)\n",
    "    print(month, location_count.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['14', '24', '6', '15', '12', '7', '1', '11', '18', '22', '5', '16', '9', '8', '3', '2', '19', '10', '4', '17', '20', '25', '31'])\n"
     ]
    }
   ],
   "source": [
    "# crimes by district\n",
    "csvfile = open('data/chicago_crime.csv', 'r')\n",
    "\n",
    "crimes_by_district = defaultdict(list)\n",
    "\n",
    "for row in csv.DictReader(csvfile):\n",
    "    # Pop the district from each row\n",
    "    district = row.pop('District')\n",
    "    \n",
    "    # Append the rest of the data to the list for proper district in crimes_by_district\n",
    "    crimes_by_district[district].append(row)\n",
    "    \n",
    "print(crimes_by_district.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('Date', '02/15/2016 04:45:00 AM'), ('Block', '029XX N LOTUS AVE'), ('Primary Type', 'BURGLARY'), ('Description', 'FORCIBLE ENTRY'), ('Location Description', 'RESIDENCE-GARAGE'), ('Arrest', 'false'), ('Domestic', 'false')]), OrderedDict([('Date', '02/13/2017 10:45:00 AM'), ('Block', '014XX N LEAMINGTON AVE'), ('Primary Type', 'CRIMINAL DAMAGE'), ('Description', 'TO PROPERTY'), ('Location Description', 'SCHOOL, PUBLIC, BUILDING'), ('Arrest', 'false'), ('Domestic', 'false')]), OrderedDict([('Date', '07/17/2016 11:25:00 AM'), ('Block', '049XX W ST PAUL AVE'), ('Primary Type', 'CRIMINAL DAMAGE'), ('Description', 'TO PROPERTY'), ('Location Description', 'APARTMENT'), ('Arrest', 'false'), ('Domestic', 'false')]), OrderedDict([('Date', '02/05/2017 05:30:00 AM'), ('Block', '051XX W DIVERSEY AVE'), ('Primary Type', 'BATTERY'), ('Description', 'DOMESTIC BATTERY SIMPLE'), ('Location Description', 'APARTMENT'), ('Arrest', 'true'), ('Domestic', 'true')]), OrderedDict([('Date', '11/07/2016 10:30:00 AM'), ('Block', '048XX W ALTGELD ST'), ('Primary Type', 'THEFT'), ('Description', '$500 AND UNDER'), ('Location Description', 'RESIDENTIAL YARD (FRONT/BACK)'), ('Arrest', 'false'), ('Domestic', 'false')])]\n"
     ]
    }
   ],
   "source": [
    "print(crimes_by_district['25'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 Counter({2016: 59, 2017: 8})\n",
      "24 Counter({2016: 51, 2017: 10})\n",
      "6 Counter({2016: 157, 2017: 32})\n",
      "15 Counter({2016: 154, 2017: 16})\n",
      "12 Counter({2016: 72, 2017: 9})\n",
      "7 Counter({2016: 181, 2017: 27})\n",
      "1 Counter({2016: 124, 2017: 15})\n",
      "11 Counter({2016: 275, 2017: 53})\n",
      "18 Counter({2016: 92, 2017: 17})\n",
      "22 Counter({2016: 78, 2017: 12})\n",
      "5 Counter({2016: 149, 2017: 30})\n",
      "16 Counter({2016: 66, 2017: 9})\n",
      "9 Counter({2016: 116, 2017: 17})\n",
      "8 Counter({2016: 124, 2017: 26})\n",
      "3 Counter({2016: 98, 2017: 18})\n",
      "2 Counter({2016: 84, 2017: 15})\n",
      "19 Counter({2016: 88, 2017: 11})\n",
      "10 Counter({2016: 144, 2017: 20})\n",
      "4 Counter({2016: 134, 2017: 15})\n",
      "17 Counter({2016: 38, 2017: 5})\n",
      "20 Counter({2016: 27, 2017: 8})\n",
      "25 Counter({2016: 150, 2017: 26})\n",
      "31 Counter({2016: 1})\n"
     ]
    }
   ],
   "source": [
    "# Arrest count by District by Year\n",
    "for district, crimes in crimes_by_district.items():\n",
    "    year_count = Counter()\n",
    "\n",
    "    for crime in crimes:\n",
    "        # If there was an arrest\n",
    "        if crime['Arrest'] == 'true':\n",
    "            year = datetime.strptime(crime['Date'], '%m/%d/%Y %I:%M:%S %p').year\n",
    "            year_count[year] += 1\n",
    "            \n",
    "    print(district, year_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9195\n"
     ]
    }
   ],
   "source": [
    "csvfile = open('data/chicago_crime.csv', 'r')\n",
    "\n",
    "crimes_by_block = defaultdict(list)\n",
    "\n",
    "for row in csv.DictReader(csvfile):\n",
    "    crimes_by_block[row['Block']].append(row['Primary Type'])\n",
    "    \n",
    "print(len(crimes_by_block.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ASSAULT', 'THEFT', 'CRIMINAL DAMAGE', 'DECEPTIVE PRACTICE', 'OTHER OFFENSE', 'CRIMINAL TRESPASS', 'BATTERY', 'ROBBERY'}\n",
      "{'ASSAULT', 'THEFT', 'PUBLIC PEACE VIOLATION', 'CRIMINAL DAMAGE', 'DECEPTIVE PRACTICE', 'OTHER OFFENSE', 'CRIMINAL TRESPASS', 'NARCOTICS'}\n",
      "{'ROBBERY', 'BATTERY'}\n"
     ]
    }
   ],
   "source": [
    "n_state_st_crimes = set(crimes_by_block['001XX N STATE ST'])\n",
    "print(n_state_st_crimes)\n",
    "\n",
    "w_terminal_st_crimes = set(crimes_by_block['0000X W TERMINAL ST'])\n",
    "print(w_terminal_st_crimes)\n",
    "\n",
    "# Find the differences\n",
    "crime_differences = n_state_st_crimes.difference(w_terminal_st_crimes)\n",
    "print(crime_differences)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
