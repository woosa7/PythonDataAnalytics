{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging (bootstrapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  floors  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00     1.0   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25     2.0   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00     1.0   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00     1.0   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00     1.0   \n",
       "\n",
       "   waterfront  condition  grade  yr_built  yr_renovated  zipcode      lat  \\\n",
       "0           0          3      7      1955             0    98178  47.5112   \n",
       "1           0          3      7      1951          1991    98125  47.7210   \n",
       "2           0          3      6      1933             0    98028  47.7379   \n",
       "3           0          5      7      1965             0    98136  47.5208   \n",
       "4           0          3      8      1987             0    98074  47.6168   \n",
       "\n",
       "      long  \n",
       "0 -122.257  \n",
       "1 -122.319  \n",
       "2 -122.233  \n",
       "3 -122.393  \n",
       "4 -122.045  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "data = pd.read_csv(\"./data/kc_house_data.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nid: 집 고유아이디\\ndate: 집이 팔린 날짜 \\nprice: 집 가격 (타겟변수)\\nbedrooms: 주택 당 침실 개수\\nbathrooms: 주택 당 화장실 개수\\nfloors: 전체 층 개수\\nwaterfront: 해변이 보이는지 (0, 1)\\ncondition: 집 청소상태 (1~5)\\ngrade: King County grading system 으로 인한 평점 (1~13)\\nyr_built: 집이 지어진 년도\\nyr_renovated: 집이 리모델링 된 년도\\nzipcode: 우편번호\\nlat: 위도\\nlong: 경도\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "id: 집 고유아이디\n",
    "date: 집이 팔린 날짜 \n",
    "price: 집 가격 (타겟변수)\n",
    "bedrooms: 주택 당 침실 개수\n",
    "bathrooms: 주택 당 화장실 개수\n",
    "floors: 전체 층 개수\n",
    "waterfront: 해변이 보이는지 (0, 1)\n",
    "condition: 집 청소상태 (1~5)\n",
    "grade: King County grading system 으로 인한 평점 (1~13)\n",
    "yr_built: 집이 지어진 년도\n",
    "yr_renovated: 집이 리모델링 된 년도\n",
    "zipcode: 우편번호\n",
    "lat: 위도\n",
    "long: 경도\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nCar: 21613 nVar: 14\n"
     ]
    }
   ],
   "source": [
    "nCar = data.shape[0]\n",
    "nVar = data.shape[1]\n",
    "print('nCar: %d' % nCar, 'nVar: %d' % nVar )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 의미가 없다고 판단되는 변수 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id', 'date', 'zipcode', 'lat', 'long'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 범주형 변수를 이진형 변수로 변환\n",
    "- 범주형 변수는 waterfront 컬럼 뿐이며, 이진 분류이기 때문에 0, 1로 표현한다.\n",
    "- 데이터에서 0, 1로 표현되어 있으므로 과정 생략"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 8) (6484, 8) (15129,) (6484,)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = list(data.columns.difference(['price'])) # Price를 제외한 모든 행\n",
    "X = data[feature_columns]\n",
    "y = data['price']\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.3, random_state = 42) # 학습데이터와 평가데이터의 비율을 7:3\n",
    "print(train_x.shape, test_x.shape, train_y.shape, test_y.shape) # 데이터 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 선형 회귀 모형에 적합 후 평가 데이터로 검증 (Stats_Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>price</td>      <th>  R-squared:         </th>  <td>   0.595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.595</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2776.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 30 Jul 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:36:25</td>     <th>  Log-Likelihood:    </th> <td>-2.0826e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15129</td>      <th>  AIC:               </th>  <td>4.165e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15120</td>      <th>  BIC:               </th>  <td>4.166e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td> 7.186e+06</td> <td> 1.73e+05</td> <td>   41.548</td> <td> 0.000</td> <td> 6.85e+06</td> <td> 7.52e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>    <td> 1.303e+05</td> <td> 3960.833</td> <td>   32.889</td> <td> 0.000</td> <td> 1.23e+05</td> <td> 1.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th>     <td>-2224.7910</td> <td> 2382.356</td> <td>   -0.934</td> <td> 0.350</td> <td>-6894.497</td> <td> 2444.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>condition</th>    <td> 1.641e+04</td> <td> 3169.013</td> <td>    5.178</td> <td> 0.000</td> <td> 1.02e+04</td> <td> 2.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>floors</th>       <td> 1946.3052</td> <td> 4336.838</td> <td>    0.449</td> <td> 0.654</td> <td>-6554.422</td> <td> 1.04e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>grade</th>        <td> 1.956e+05</td> <td> 2199.540</td> <td>   88.924</td> <td> 0.000</td> <td> 1.91e+05</td> <td>    2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>waterfront</th>   <td> 7.555e+05</td> <td> 2.26e+04</td> <td>   33.479</td> <td> 0.000</td> <td> 7.11e+05</td> <td>    8e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_built</th>     <td>-4300.7865</td> <td>   88.073</td> <td>  -48.832</td> <td> 0.000</td> <td>-4473.420</td> <td>-4128.153</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>yr_renovated</th> <td>   12.7325</td> <td>    5.043</td> <td>    2.525</td> <td> 0.012</td> <td>    2.847</td> <td>   22.618</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>13447.374</td> <th>  Durbin-Watson:     </th>  <td>   1.994</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>1684794.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.763</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>54.147</td>   <th>  Cond. No.          </th>  <td>1.82e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.82e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  price   R-squared:                       0.595\n",
       "Model:                            OLS   Adj. R-squared:                  0.595\n",
       "Method:                 Least Squares   F-statistic:                     2776.\n",
       "Date:                Thu, 30 Jul 2020   Prob (F-statistic):               0.00\n",
       "Time:                        17:36:25   Log-Likelihood:            -2.0826e+05\n",
       "No. Observations:               15129   AIC:                         4.165e+05\n",
       "Df Residuals:                   15120   BIC:                         4.166e+05\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const         7.186e+06   1.73e+05     41.548      0.000    6.85e+06    7.52e+06\n",
       "bathrooms     1.303e+05   3960.833     32.889      0.000    1.23e+05    1.38e+05\n",
       "bedrooms     -2224.7910   2382.356     -0.934      0.350   -6894.497    2444.915\n",
       "condition     1.641e+04   3169.013      5.178      0.000    1.02e+04    2.26e+04\n",
       "floors        1946.3052   4336.838      0.449      0.654   -6554.422    1.04e+04\n",
       "grade         1.956e+05   2199.540     88.924      0.000    1.91e+05       2e+05\n",
       "waterfront    7.555e+05   2.26e+04     33.479      0.000    7.11e+05       8e+05\n",
       "yr_built     -4300.7865     88.073    -48.832      0.000   -4473.420   -4128.153\n",
       "yr_renovated    12.7325      5.043      2.525      0.012       2.847      22.618\n",
       "==============================================================================\n",
       "Omnibus:                    13447.374   Durbin-Watson:                   1.994\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1684794.827\n",
       "Skew:                           3.763   Prob(JB):                         0.00\n",
       "Kurtosis:                      54.147   Cond. No.                     1.82e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.82e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "sm_train_x = sm.add_constant(train_x, has_constant = 'add') # Bias 추가\n",
    "sm_model = sm.OLS(train_y, sm_train_x) # 모델 구축\n",
    "fitted_sm_model = sm_model.fit() # 학습 진행\n",
    "fitted_sm_model.summary() # 학습 모델 구조 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239804.2967085816\n",
      "\n",
      "const           7.185671e+06\n",
      "bathrooms       1.302689e+05\n",
      "bedrooms       -2.224791e+03\n",
      "condition       1.641020e+04\n",
      "floors          1.946305e+03\n",
      "grade           1.955909e+05\n",
      "waterfront      7.555423e+05\n",
      "yr_built       -4.300787e+03\n",
      "yr_renovated    1.273246e+01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "sm_test_x = sm.add_constant(test_x, has_constant = 'add') # 테스트 데이터에 Bias 추가\n",
    "sm_model_predict = fitted_sm_model.predict(sm_test_x) # 테스트 데이터 예측\n",
    "print(\"RMSE: {}\\n\".format(sqrt(mean_squared_error(sm_model_predict, test_y)))) # RMSE\n",
    "print(fitted_sm_model.params) # 회귀계수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 한 결과가 일반적인 결과보다 좋은지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9587\n",
      "9576\n",
      "9593\n",
      "9571\n",
      "9540\n",
      "9575\n",
      "9635\n",
      "9571\n",
      "9577\n",
      "9592\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "bagging_predict_result = [] # 빈 리스트 생성\n",
    "\n",
    "for _ in range(10):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])] # 학습 데이터의 인덱스를 리스트로 변환\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0]) # 데이터의 1/10 크기만큼 랜덤 샘플링, // 는 소수점을 무시하기 위함\n",
    "    print(len(set(random_data_index)))\n",
    "    sm_train_x = train_x.iloc[random_data_index, ] # 랜덤 인덱스에 해당되는 학습 데이터 중 설명 변수\n",
    "    sm_train_y = train_y.iloc[random_data_index, ] # 랜덤 인덱스에 해당되는 학습 데이터 중 종속 변수\n",
    "    sm_train_x = sm.add_constant(sm_train_x, has_constant = 'add') # Bias 추가\n",
    "    sm_model = sm.OLS(sm_train_y, sm_train_x) # 모델 구축\n",
    "    fitted_sm_model = sm_model.fit() # 학습 진행\n",
    "    \n",
    "    sm_test_x = sm.add_constant(test_x, has_constant = 'add') # 테스트 데이터에 Bias 추가\n",
    "    sm_model_predict = fitted_sm_model.predict(sm_test_x) # 테스트 데이터 예측\n",
    "    bagging_predict_result.append(sm_model_predict) # 반복문이 실행되기 전 빈 리스트에 결과 값 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "735      5.640296e+05\n",
       "2830     7.184781e+05\n",
       "4106     1.121120e+06\n",
       "16218    1.487513e+06\n",
       "19964    7.047517e+05\n",
       "             ...     \n",
       "12606    6.064193e+05\n",
       "14393    6.801028e+05\n",
       "6899     3.218954e+05\n",
       "85       9.039520e+05\n",
       "21363    4.374061e+05\n",
       "Length: 6484, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict_result[0] # 0 ~ 9, 10번의 예측을 하였기 때문에 10개의 결과가 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bagging을 바탕으로 예측한 결과값에 대한 평균을 계산\n",
    "bagging_predict = [] # 빈 리스트 생성\n",
    "for lst2_index in range(test_x.shape[0]): # 테스트 데이터 개수만큼의 반복\n",
    "    temp_predict = [] # 임시 빈 리스트 생성 (반복문 내 결과값 저장)\n",
    "    for lst_index in range(len(bagging_predict_result)): # Bagging 결과 리스트 반복\n",
    "        temp_predict.append(bagging_predict_result[lst_index].values[lst2_index]) # 각 Bagging 결과 예측한 값 중 같은 인덱스를 리스트에 저장\n",
    "    bagging_predict.append(np.mean(temp_predict)) # 해당 인덱스의 30개의 결과값에 대한 평균을 최종 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239771.0397124748\n"
     ]
    }
   ],
   "source": [
    "# 예측한 결과값들의 평균을 계산하여 실제 테스트 데이트의 타겟변수와 비교하여 성능 평가\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(bagging_predict, test_y)))) # RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 선형 회귀 모형에 적합 후 평가 데이터로 검증 (Scikit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239804.29670858145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regression_model = LinearRegression() # 선형 회귀 모형\n",
    "linear_model1 = regression_model.fit(train_x, train_y) # 학습 데이터를 선형 회귀 모형에 적합\n",
    "predict1 = linear_model1.predict(test_x) # 학습된 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict1, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 선형 회귀 모형에 적합 후 평가 (Sampling 10번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239936.4471006533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "bagging_model = BaggingRegressor(base_estimator = regression_model, # 선형회귀모형\n",
    "                                 n_estimators = 5, # 5번 샘플링\n",
    "                                 verbose = 1) # 학습 과정 표시\n",
    "linear_model2 = bagging_model.fit(train_x, train_y) # 학습 진행\n",
    "predict2 = linear_model2.predict(test_x) # 학습된 Bagging 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict2, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그렇다면 Sampling을 많이 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 239838.5686255727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_model2 = BaggingRegressor(base_estimator = regression_model, # 선형 회귀모형\n",
    "                                  n_estimators = 30, # 30번 샘플링\n",
    "                                  verbose = 1) # 학습 과정 표시\n",
    "linear_model3 = bagging_model2.fit(train_x, train_y) # 학습 진행\n",
    "predict3 = linear_model3.predict(test_x) # 학습된 Bagging 선형 회귀 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict3, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터를 의사결정나무모형에 적합 후 평가 데이터로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 284298.1676879424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision_tree_model = DecisionTreeRegressor() # 의사결정나무 모형\n",
    "tree_model1 = decision_tree_model.fit(train_x, train_y) # 학습 데이터를 의사결정나무 모형에 적합\n",
    "predict1 = tree_model1.predict(test_x) # 학습된 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict1, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9582\n",
      "9551\n",
      "9579\n",
      "9521\n",
      "9643\n",
      "9552\n",
      "9550\n",
      "9551\n",
      "9562\n",
      "9483\n",
      "9567\n",
      "9552\n",
      "9576\n",
      "9559\n",
      "9571\n",
      "9520\n",
      "9671\n",
      "9516\n",
      "9578\n",
      "9579\n",
      "9531\n",
      "9494\n",
      "9548\n",
      "9545\n",
      "9550\n",
      "9576\n",
      "9580\n",
      "9583\n",
      "9533\n",
      "9633\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "bagging_predict_result = [] # 빈 리스트 생성\n",
    "for _ in range(30):\n",
    "    data_index = [data_index for data_index in range(train_x.shape[0])] # 학습 데이터의 인덱스를 리스트로 변환\n",
    "    random_data_index = np.random.choice(data_index, train_x.shape[0]) # 데이터의 1/10 크기만큼 랜덤 샘플링, // 는 소수점을 무시하기 위함\n",
    "    print(len(set(random_data_index)))\n",
    "    sm_train_x = train_x.iloc[random_data_index, ] # 랜덤 인덱스에 해당되는 학습 데이터 중 설명 변수\n",
    "    sm_train_y = train_y.iloc[random_data_index, ] # 랜덤 인덱스에 해당되는 학습 데이터 중 종속 변수\n",
    "    decision_tree_model = DecisionTreeRegressor() # 의사결정나무 모형\n",
    "    tree_model1 = decision_tree_model.fit(sm_train_x, sm_train_y) # 학습 데이터를 의사결정나무 모형에 적합\n",
    " \n",
    "    predict1 = tree_model1.predict(test_x) # 테스트 데이터 예측\n",
    "    bagging_predict_result.append(predict1) # 반복문이 실행되기 전 빈 리스트에 결과 값 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Bagging을 바탕으로 예측한 결과값에 대한 평균을 계산\n",
    "bagging_predict = [] # 빈 리스트 생성\n",
    "for lst2_index in range(test_x.shape[0]): # 테스트 데이터 개수만큼의 반복\n",
    "    temp_predict = [] # 임시 빈 리스트 생성 (반복문 내 결과값 저장)\n",
    "    for lst_index in range(len(bagging_predict_result)): # Bagging 결과 리스트 반복\n",
    "        temp_predict.append(bagging_predict_result[lst_index][lst2_index]) # 각 Bagging 결과 예측한 값 중 같은 인덱스를 리스트에 저장\n",
    "    bagging_predict.append(np.mean(temp_predict)) # 해당 인덱스의 30개의 결과값에 대한 평균을 최종 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 237399.69910405998\n"
     ]
    }
   ],
   "source": [
    "# 예측한 결과값들의 평균을 계산하여 실제 테스트 데이트의 타겟변수와 비교하여 성능 평가\n",
    "\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(bagging_predict, test_y)))) # RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([322500.        , 720000.        , 925666.66666667, ...,\n",
       "       266196.08695652, 605004.        , 305000.        ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging_predict_result[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging 을 이용하여 의사결정나무모형에 적합 후 평가 (Sampling 10번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 243523.94778527206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_decision_tree_model1 = BaggingRegressor(base_estimator = decision_tree_model, # 의사결정나무 모형\n",
    "                                                n_estimators = 5, # 5번 샘플링\n",
    "                                                verbose = 1) # 학습 과정 표시\n",
    "tree_model2 = bagging_decision_tree_model1.fit(train_x, train_y) # 학습 진행\n",
    "predict2 = tree_model2.predict(test_x) # 학습된 Bagging 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict2, test_y)))) # RMSE 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 233091.59790161543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "bagging_decision_tree_model2 = BaggingRegressor(base_estimator = decision_tree_model, # 의사결정나무 모형\n",
    "                                                n_estimators = 30, # 30번 샘플링\n",
    "                                                verbose = 1) # 학습 과정 표시\n",
    "tree_model3 = bagging_decision_tree_model2.fit(train_x, train_y) # 학습 진행\n",
    "predict3 = tree_model3.predict(test_x) # 학습된 Bagging 의사결정나무 모형으로 평가 데이터 예측\n",
    "print(\"RMSE: {}\".format(sqrt(mean_squared_error(predict3, test_y)))) # RMSE 결과"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
